{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Credit Card Fraud Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data\n",
    "\n",
    "[Credit Card Fraud Detection - Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud)에서 다운받을수 있습니다.\n",
    "\n",
    "데이터는 2013년 유럽 카드회사의 이틀동안 일어난 transactions에 관한 것이며, <br>\n",
    "492건의 frauds 가 284,807건의 transactions중에 일어 났습니다.\n",
    "\n",
    "Class에서 1은 fraud를 뜻하며, 0은 아닌것을 말합니다.\n",
    "\n",
    "Time데이터는 첫번재 Column으로부터 몇초 이후에 발생한 transaction이라는 뜻입니다. <br>\n",
    "나머지 데이터들은 PCA의 규제에 의해서 어떤 데이터인지 밝히지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/dataset/credit-card-fraud-detection/creditcard.csv')\n",
    "\n",
    "# Preprocessing Amount\n",
    "amt_scale = MinMaxScaler()\n",
    "data['NormAmount'] =  amt_scale.fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "# Split Train and Test Data\n",
    "X = data.drop(['Time', 'Amount', 'Class'], axis=1).as_matrix()\n",
    "Y = data['Class'].as_matrix()\n",
    "\n",
    "# Standardization\n",
    "scale_x = MinMaxScaler()\n",
    "X = scale_x.fit_transform(X)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "\n",
    "fraud_test_y = test_y == 1\n",
    "fraud_test_x = test_x[fraud_test_y]\n",
    "fraud_test_y = test_y[fraud_test_y]\n",
    "\n",
    "train_category_y = np_utils.to_categorical(train_y)\n",
    "test_category_y = np_utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Checking the number of fraud transactions in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Fraud transactions in Training Data: 381\n",
      "The number of Fraud transactions in Test Data: 111\n"
     ]
    }
   ],
   "source": [
    "print('The number of Fraud transactions in Training Data:', train_y[train_y == 1].shape[0])\n",
    "print('The number of Fraud transactions in Test Data:',  test_y[test_y == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Checking the target classes\n",
    "\n",
    "fraud transactions이 492개밖에 되지 않기 때문에, 일반적인 classification algorithm으로 돌리면 물론 정확도는 매우 높게 나오지만.. \n",
    "실상은 1에 해당하는 fraud transactions에서는 대부분 틀릴 가능성이 매우 높습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['Class'], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Resampling\n",
    "\n",
    "resampling에는 여러가지 방법이 있습니다. \n",
    "\n",
    "1. Over Sampling: SMOTE (Synthetic Minority Over-Sampling Technique)\n",
    "2. Under Sampling\n",
    "\n",
    "아래의 resample function에서는 5:5의 비율로 under sampling을 해줍니다.<br>\n",
    "resample을 하면서 시간관계가 어차피 깨지기 때문에 (사실 각각의 transactions들 사이에 상관관계가 있는지도 모르겠음)<br>\n",
    "shuffle을 통해서 train되는 데이터를 augment해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampled_train_x: (762, 29)\n",
      "resampled_train_y: (762,)\n"
     ]
    }
   ],
   "source": [
    "def resample(X, Y, ratio=1.):\n",
    "    index = np.arange(Y.shape[0])\n",
    "    fraud_indices = index[Y == 1]\n",
    "    normal_indices = index[Y == 0]\n",
    "    normal_n = int(len(fraud_indices) * ratio)\n",
    "    \n",
    "    random_normal_indices = np.random.permutation(normal_indices)[:normal_n]\n",
    "    \n",
    "    sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "    np.random.shuffle(sample_indices)\n",
    "    sample_indices = np.array(sample_indices)\n",
    "    \n",
    "    sample_x = X[sample_indices]\n",
    "    sample_y = Y[sample_indices]\n",
    "    return sample_x, sample_y\n",
    "\n",
    "resampled_train_x, resampled_train_y = resample(train_x, train_y)\n",
    "\n",
    "print('resampled_train_x:', resampled_train_x.shape)\n",
    "print('resampled_train_y:', resampled_train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "전체적으로 0.99% accuracy를 보이지만, 실제 fraud data만 test를 했을때는 0.57%로.. 실질적으로 못맞추는 수준입니다.<br>\n",
    "사실 일반적인 알고리즘으로 학습시키기 위해서는 over sampling (SMOTE 같은) 또는 under sampling이 필요합니다.<br>\n",
    "sampling을 통해서 skewed data를 보정하는 것입니다.\n",
    "\n",
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99908710429482317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(train_x, train_y)\n",
    "predicted_y = lg.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51351351351351349"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = lg.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### resampled data로 학습뒤 예측하면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970506446448133"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(*resample(train_x, train_y))\n",
    "\n",
    "predicted_y = lg.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77477477477477474"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = lg.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decision Tree\n",
    "\n",
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99925563888654811"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, criterion='entropy')\n",
    "dtc.fit(train_x, train_y)\n",
    "predicted_y = dtc.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72972972972972971"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = dtc.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### resampled data로 학습뒤 예측하면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899974719811\n",
      "0.913345130755\n",
      "0.911154181062\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, criterion='entropy')\n",
    "for i in range(3):\n",
    "    dtc.fit(*resample(train_x, train_y))\n",
    "    predicted_y = dtc.predict(test_x)\n",
    "    print(accuracy_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91891891891891897"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = dtc.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Learning with Keras\n",
    "\n",
    "하.. 드디어 딥러닝으로.. 해보면 어떤 결과가 나올 것인가.. Sampling VS UnSampling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense01 (Dense)              (None, 762)               22860     \n",
      "_________________________________________________________________\n",
      "activation01 (Activation)    (None, 762)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 762)               0         \n",
      "_________________________________________________________________\n",
      "dense02 (Dense)              (None, 512)               390656    \n",
      "_________________________________________________________________\n",
      "activation02 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense03 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation03 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense04 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation04 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense05 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation05 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 577,869\n",
      "Trainable params: 577,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(762, input_dim=29, name='dense01'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Activation('relu', name='activation01'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, name='dense02'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Activation('relu', name='activation02'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, name='dense03'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Activation('relu', name='activation03'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(128, name='dense04'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Activation('relu', name='activation04'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(1, name='dense05'))\n",
    "    model.add(Activation('relu', name='activation05'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# # Visualization\n",
    "model = generate_model()\n",
    "model.summary()\n",
    "# SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 2/10\n",
      "38s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 3/10\n",
      "41s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 4/10\n",
      "40s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 5/10\n",
      "42s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 6/10\n",
      "41s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 7/10\n",
      "41s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 8/10\n",
      "42s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 9/10\n",
      "41s - loss: 0.0287 - acc: 0.9982\n",
      "Epoch 10/10\n",
      "43s - loss: 0.0287 - acc: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86656c1c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generate_model()\n",
    "model.fit(train_x, train_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998441055027\n"
     ]
    }
   ],
   "source": [
    "predicted_y = model.predict(test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "predicted_y = np.where(predicted_y >= 0.5, 1, 0)\n",
    "print(accuracy_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = model.predict(fraud_test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "predicted_y = np.where(predicted_y >= 0.5, 1, 0)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### resampled data로 학습뒤 예측하면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1] epoch:17 loss:0.249    acc:0.9023  \n",
      "[ 2] epoch:40 loss:0.1844   acc:0.9344  \n",
      "[ 3] epoch:14 loss:0.1807   acc:0.9353  \n",
      "[ 4] epoch:32 loss:0.1804   acc:0.9366  \n",
      "[ 5] epoch:13 loss:0.1717   acc:0.9379  \n",
      "[ 6] epoch:33 loss:0.1773   acc:0.9347  \n",
      "[ 7] epoch:16 loss:0.176    acc:0.9364  \n",
      "[ 8] epoch:19 loss:0.1666   acc:0.9417  \n",
      "[ 9] epoch:24 loss:0.177    acc:0.9352  \n",
      "[10] epoch:17 loss:0.1728   acc:0.938   \n",
      "[11] epoch:24 loss:0.1601   acc:0.9424  \n",
      "[12] epoch:25 loss:0.1685   acc:0.9371  \n",
      "[13] epoch:17 loss:0.1716   acc:0.9372  \n",
      "[14] epoch:14 loss:0.1743   acc:0.9364  \n",
      "[15] epoch:16 loss:0.1645   acc:0.94    \n",
      "[16] epoch:17 loss:0.1847   acc:0.9332  \n",
      "[17] epoch:14 loss:0.1611   acc:0.9433  \n",
      "[18] epoch:34 loss:0.1484   acc:0.9474  \n",
      "[19] epoch:42 loss:0.1595   acc:0.9423  \n",
      "[20] epoch:29 loss:0.1576   acc:0.9432  \n",
      "[21] epoch:14 loss:0.1708   acc:0.9382  \n",
      "[22] epoch:34 loss:0.1558   acc:0.9441  \n",
      "[23] epoch:19 loss:0.1502   acc:0.9487  \n",
      "[24] epoch:18 loss:0.1648   acc:0.9413  \n",
      "[25] epoch:27 loss:0.1684   acc:0.9392  \n",
      "[26] epoch:24 loss:0.1514   acc:0.9459  \n",
      "[27] epoch:18 loss:0.1578   acc:0.9443  \n",
      "[28] epoch:19 loss:0.174    acc:0.9338  \n",
      "[29] epoch:44 loss:0.1527   acc:0.9448  \n",
      "[30] epoch:13 loss:0.1638   acc:0.9409  \n",
      "[31] epoch:24 loss:0.1535   acc:0.9431  \n",
      "[32] epoch:23 loss:0.1588   acc:0.9417  \n",
      "[33] epoch:18 loss:0.1669   acc:0.9378  \n",
      "[34] epoch:20 loss:0.1639   acc:0.9382  \n",
      "[35] epoch:23 loss:0.1513   acc:0.944   \n",
      "[36] epoch:16 loss:0.1584   acc:0.9416  \n",
      "[37] epoch:24 loss:0.1555   acc:0.942   \n",
      "[38] epoch:35 loss:0.1614   acc:0.9391  \n",
      "[39] epoch:12 loss:0.1498   acc:0.9472  \n",
      "[40] epoch:14 loss:0.1636   acc:0.937   \n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    np.random.seed(0)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(384, input_dim=29))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(204))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(157))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# # Visualization\n",
    "model = generate_model()\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "for i in range(40):\n",
    "    _train_data = resample(train_x, train_y)\n",
    "        \n",
    "    history = model.fit(*_train_data,\n",
    "                        verbose=0, \n",
    "                        epochs=100,\n",
    "                        callbacks=[early_stopping])\n",
    "    loss = np.mean(history.history.get('loss'))\n",
    "    acc = np.mean(history.history.get('acc'))\n",
    "    epoch = len(history.epoch)\n",
    "    print(f'[{i+1:2}] epoch:{epoch:<2} loss:{loss:<8.4} acc:{acc:<8.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98391899104\n"
     ]
    }
   ],
   "source": [
    "predicted_y = model.predict(test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "predicted_y = np.where(predicted_y >= 0.5, 1, 0)\n",
    "print(accuracy_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86486486486486491"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = model.predict(fraud_test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "predicted_y = np.where(predicted_y >= 0.5, 1, 0)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
